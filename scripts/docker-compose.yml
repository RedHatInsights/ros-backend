version: "3.8"
services:
  redis:
    image: quay.io/cloudservices/redis-ephemeral:6
    ports:
      - "6379:6379"
  zookeeper:
    image: confluentinc/cp-zookeeper
    environment:
      - ZOOKEEPER_CLIENT_PORT=32181
      - ZOOKEEPER_SERVER_ID=1
  kafka:
    image: confluentinc/cp-kafka
    ports:
      - 29092:29092
      - 9092:9092
    depends_on:
      - zookeeper
    environment:
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      - KAFKA_BROKER_ID=1
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:32181
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
  # Below container is to implement workaround for creating required topics.
  kafka-create-topics:
    image: confluentinc/cp-kafka
    ports:
      - 7777:29092
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
                       cub kafka-ready -b kafka:29092 1 20 && \
                       kafka-topics --create --if-not-exists --topic platform.inventory.events --bootstrap-server kafka:29092 && \
                       kafka-topics --create --if-not-exists --topic platform.engine.results --bootstrap-server kafka:29092'"
    depends_on:
      - kafka
  minio:
    image: minio/minio
    command: server /data
    volumes:
      # These vars are defined in .env
      # These are configurable
      # Ensure the directories exist prior to running this file
      - ./minio-conf/:/root/.minio:Z
      - ./minio-data/:/data:Z
    ports:
      - 9000:9000
    environment:
      - MINIO_ACCESS_KEY=$MINIO_ACCESS_KEY
      - MINIO_SECRET_KEY=$MINIO_SECRET_KEY
  createbuckets:
    image: minio/mc
    depends_on:
      - minio
    entrypoint: >
      /bin/sh -c "
      /usr/bin/mc config host add myminio http://minio:9000 $MINIO_ACCESS_KEY $MINIO_SECRET_KEY;
      /usr/bin/mc mb myminio/insights-upload-perma;
      /usr/bin/mc mb myminio/insights-upload-rejected;
      /usr/bin/mc policy download myminio/insights-upload-perma;
      /usr/bin/mc policy download myminio/insights-upload-rejected;
      exit 0;
      "
  ingress:
    image: quay.io/cloudservices/insights-ingress:latest
    ports:
      - 3000:3000
    environment:
      - INGRESS_STAGEBUCKET=insights-upload-perma
        # VALIDTOPICS is required. This is derived from content type. ex: vnd.redhat.advisor.thing+tgz
      - INGRESS_VALIDTOPICS=testareno,advisor,compliance,qpc
      - OPENSHIFT_BUILD_COMMIT=somestring
      - INGRESS_DEFAULTMAXSIZE=104857600
      - INGRESS_MINIODEV=true
      - INGRESS_MINIOACCESSKEY=$MINIO_ACCESS_KEY
      - INGRESS_MINIOSECRETKEY=$MINIO_SECRET_KEY
      - INGRESS_MINIOENDPOINT=minio:9000
    depends_on:
       - createbuckets
       - kafka
  db-ros:
    image: postgres
    restart: always
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER: postgres
      POSTGRES_DB: postgres
    ports:
      - "15432:5432"
  db-host-inventory:
    image: debezium/postgres
    restart: always
    environment:
      POSTGRES_PASSWORD: insights
      POSTGRES_USER: insights
      POSTGRES_DB: insights
    ports:
      - "15433:5432"

  insights-inventory-mq: &inventory
    image: quay.io/cloudservices/insights-inventory:latest
    restart: always
    command: "make upgrade_db run_inv_mq_service"
    environment:
      - APP_NAME=inventory
      - PATH_PREFIX=api
      - INVENTORY_DB_USER=insights
      - INVENTORY_DB_PASS=insights
      - INVENTORY_DB_HOST=db-host-inventory
      - INVENTORY_DB_NAME=insights
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - PAYLOAD_TRACKER_ENABLED=false
      - XJOIN_GRAPHQL_URL=http://xjoin:4000/graphql
      - prometheus_multiproc_dir=/tmp
    depends_on:
       - kafka-create-topics
       - db-host-inventory
       - puptoo
       - createbuckets

  insights-inventory-web:
    <<: *inventory
    command: "make upgrade_db run_inv_web_service"
    depends_on:
      - insights-inventory-mq
    ports:
      - 8001:8080

  puptoo:
    image: quay.io/cloudservices/insights-puptoo:latest
    ports:
      - 8003:8003
    environment:
      - LOG_LEVEL=INFO
      - FACT_EXTRACT_LOGLEVEL=ERROR
      - KAFKA_ALLOW_CREATE_TOPICS=True
      - DISABLE_PROMETHEUS=True
    depends_on:
      - kafka
      - ingress
    # Not yet used, we are not running clowder ATM
    volumes:
      - './cdappconfig.json:/cdappconfig.json:Z'

  insights-engine:
    image: quay.io/cloudservices/insights-engine:latest
    restart: always
    depends_on:
      - puptoo
      - kafka-create-topics
      - insights-inventory-mq
  # Allows us to run the application in the form it's going to be deployed, will be needed for tests
  # ros-processor: &ros
  #   build:
  #     context: ..
  #   command: [ "python", "-m", "ros.processor.main" ]
  #   depends_on:
  #     - insights-inventory-web
  #     - insights-engine
  #     - kafka
  #     - createbuckets
  #   environment:
  #     - INSIGHTS_KAFKA_HOST=kafka
  #     - INSIGHTS_KAFKA_PORT=29092
  #     - INVENTORY_HOST=insights-inventory-web
  #     - INVENTORY_PORT=8000
  #     - ROS_DB_HOST=db-ros
  #     - ROS_DB_PORT=5432
  # ros-api:
  #   <<: *ros
  #   command: ["bash", "-c", "python -m manage db upgrade && python -m manage seed && python -m ros.api.main"]
  #   ports:
  #     - 8000:8000
  # logging and Monitoring
  grafana:
      ports:
          - 3001:3000
      container_name: grafana
      environment:
          - GF_SERVER_ROOT_URL=http://grafana.server.name
          - GF_SECURITY_ADMIN_PASSWORD=secret
      image: grafana/grafana
  prometheus:
      container_name: example-prometheus
      ports:
          - 9090:9090
      extra_hosts:
          - "host.docker.internal:host-gateway"
      volumes:
          - ./prometheus.yml:/etc/prometheus/prometheus.yml
      image: prom/prometheus
  debezium:
    image: quay.io/cloudservices/xjoin-kafka-connect-strimzi
    restart: always
    entrypoint: /opt/kafka/kafka_connect_run.sh
    volumes:
      - ./xjoin-config/log4j.properties/:/opt/kafka/custom-config/log4j.properties:Z
    environment:
      - KAFKA_CONNECT_BOOTSTRAP_SERVERS=kafka:29092
      - KAFKA_CONNECT_METRICS_ENABLED=false
      - STRIMZI_KAFKA_GC_LOG_ENABLED=false
      - |
        KAFKA_CONNECT_CONFIGURATION=
        offset.storage.topic=connect-cluster-offsets
        value.converter=org.apache.kafka.connect.json.JsonConverter
        config.storage.topic=connect-cluster-configs
        key.converter=org.apache.kafka.connect.json.JsonConverter
        group.id=connect-cluster
        status.storage.topic=connect-cluster-status
        config.storage.replication.factor=1
        connector.client.config.override.policy=All
        offset.storage.replication.factor=1
        status.storage.replication.factor=1
    depends_on:
      - kafka
      - db-host-inventory
      - insights-inventory-mq
    ports:
      - 8083:8083
  elasticsearch:
    restart: always
    image: elasticsearch:7.10.1
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - cluster.routing.allocation.disk.threshold_enabled=false
  xjoin:
    image: quay.io/cloudservices/xjoin-search:3c3f8b0
    restart: always
    environment:
      - LOG_LEVEL=debug
      - LOG_PRETTY=false
      - NODE_ENV=development
      - ES_NODES=http://elasticsearch:9200
      - HOSTS_INDEX=xjoin.inventory
    ports:
      - 4000:4000
    depends_on:
      - elasticsearch
      - debezium
